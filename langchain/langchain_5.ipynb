{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading OpenAI Key\n",
    "OPENAI_API_KEY=input(\"Enter OpenAI API Key\")\n",
    "#Reading Langchain API Key\n",
    "LANGCHAIN_API_KEY=input(\"Enter Langchain API Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enabiling Langchain Tracing\n",
    "LANGCHAIN_TRACING_V2= \"true\"\n",
    "#OpenAI Model\n",
    "OPENAI_MODEL=\"gpt-4o-mini\"\n",
    "LANGCHAIN_TRACING_V2=\"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing langchain_openai package\n",
    "! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10fed5940>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10fed6ed0>, root_client=<openai.OpenAI object at 0x10f5bc7a0>, root_async_client=<openai.AsyncOpenAI object at 0x10fed5970>, model_name='gpt-4o-mini', temperature=0.5, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing llm\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=OPENAI_MODEL,openai_api_key=OPENAI_API_KEY,temperature=0.5)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Python package for SQLDatabase\n",
    "! pip install langchain-community==0.2.9\n",
    "! pip install sqlalchemy==2.0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.utilities.sql_database.SQLDatabase at 0x119d435c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initializing Database object\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"sqlite:///baggage_tracking.db\")\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import BaseGenerationOutputParser\n",
    "from typing import List\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.outputs import  Generation\n",
    "class SQlExtractParser(BaseGenerationOutputParser[str]):\n",
    "    \"\"\"\n",
    "    A parser for SQL output.\n",
    "    \"\"\"\n",
    "\n",
    "    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:\n",
    "        \"\"\"\n",
    "        Parse the SQL query input and return the extracted SQL query.\n",
    "\n",
    "        Args:\n",
    "            sql_query_input (str): The input SQL query string.\n",
    "            partial (bool, optional): Whether the input is a partial query. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            str: The extracted SQL query.\n",
    "        \"\"\"\n",
    "        if not result:\n",
    "            raise OutputParserException(\"Input SQL query is empty\")\n",
    "        \n",
    "        print(f\"Incoming query {result[0]}\")\n",
    "\n",
    "        if 'SQLQuery:' in result[0].text:\n",
    "            sql_query = result[0].text.split('SQLQuery:', 1)[1].strip()\n",
    "            print(f\"Extracted SQL query: {sql_query}\")\n",
    "        else:\n",
    "            sql_query = result[0].text\n",
    "\n",
    "        return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_examples = [\n",
    "    {\n",
    "        \"input\": \"Show bag tag numbers for the PNR number AAA100\",\n",
    "        \"query\": \"select bag_tag_number from baggage_details where pnr = 'AAA100';\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find the baggage details of the flight originating from JFK and destination is SFO\",\n",
    "        \"query\": \"select * from baggage_details where origin ='JFK' and destination ='SFO';\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find scanning details of bag tag number 001234567890\",\n",
    "        \"query\": \"SELECT * from baggage_scanning where bag_tag_number = '001234567890';\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find the passengers in flight BC101\",\n",
    "        \"query\": \"SELECT * from passenger_details where passenger_flight_number = 'BC101';\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find the passenger details for the bag tag number 001234567890\",\n",
    "        \"query\": \"SELECT * from passenger_details where bag_tag_number = '001234567890'\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find rush bags in flight AB100\",\n",
    "        \"query\": \"SELECT * from baggage_details where rush_bag='Yes' and flight_number = 'AB100'\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain Example  Selector\n",
    "=====================================\n",
    "langchain_core.example_selectors is a module in LangChain that deals with selecting examples dynamically from a set of predefined examples based on the current input or prompt. This is useful when you want to choose the most relevant examples to show or use for few-shot learning, helping to improve the performance of large language models (LLMs) by providing them with more specific and contextual examples.\n",
    "\n",
    "Example Selectors dynamically pick the most relevant examples from a set, based on the input to the language model. Instead of hardcoding examples for few-shot learning, example selectors allow you to choose relevant examples based on input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# initializes an instance of a Chroma vector store.\n",
    "vector_store = Chroma()\n",
    "# deletes any existing collection in the vector store\n",
    "vector_store.delete_collection()\n",
    "#  LangChain class that helps you select examples based on their semantic similarity to a given input. \n",
    "# It uses vector embeddings (vectorized representations of text) to compare the input with examples.\n",
    "# creating creates an instance of SemanticSimilarityExampleSelector\n",
    "sql_example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    sql_examples,\n",
    "    # To transform SQL examples and input queries into embeddings (vectors), enabling semantic comparison between them.\n",
    "    OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY),\n",
    "    # This is the Chroma vector store, where embeddings of the examples will be stored and queried. \n",
    "    vector_store,\n",
    "    # This specifies that the selector should return the top 2 most similar examples. \n",
    "    k=2,\n",
    "    #  This indicates that the key \"input\" in the provided examples will be used as the query. \n",
    "    # It tells the selector what part of each example should be compared to the input query.\n",
    "    input_keys=[\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "sql_example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\\nSQLQuery:\"),\n",
    "        (\"ai\",\"{query}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "sql_few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    # This is the format/template used for each individual example in the few-shot learning setup. \n",
    "    # It defines how each example (SQL query and its corresponding result) will be presented.\n",
    "    example_prompt=sql_example_prompt,\n",
    "    # example selector that dynamically chooses the most relevant examples based on the user's input.\n",
    "    example_selector=sql_example_selector,\n",
    "    # This indicates which variables (placeholders) from the input will be used in the prompt template.\n",
    "    input_variables=[\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import  ChatPromptTemplate,MessagesPlaceholder\n",
    "SQL_QUERY_PROMPT_WITH_MEMORY=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"\"\" You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
    "         You can order the results to return the most informative data in the database.\n",
    "        Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "        Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "        Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
    "\n",
    "        Use the following format:\n",
    "\n",
    "        Question: Question here\n",
    "        SQLQuery: SQL Query to run\n",
    "        SQLResult: Result of the SQLQuery\n",
    "        Answer: Final answer here\n",
    "         \n",
    "        {top_k}\n",
    "\n",
    "        Only use the following tables:\n",
    "        {table_info}\"\"\"),\n",
    "        sql_few_shot_prompt,\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "ANSWER_PROMPTS = PromptTemplate.from_template(\n",
    "     \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "     Combine the the Question and SQL Result to generate a meaningful answer to the user.\n",
    "     The answer should be in the format of a sentence.\n",
    "     The answer should be a direct response to the user question.\n",
    "     Respond to the question as an experienced airline ground staff\n",
    "\n",
    " Question: {question}\n",
    " SQL Query: {query}\n",
    " SQL Result: {result}\n",
    " Answer: \"\"\"\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Table Selection\n",
    "========================\n",
    "\n",
    "We are making use of the table_names_to_use parameter in create_sql_query_chain\n",
    "If the user specifies \"table_names_to_use\" when invoking chain, only those will be included. Otherwise, all tables are included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "TABLE_SELECTION_PROMPT=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question.\n",
    "        The tables are:\n",
    "        {table_names}\n",
    "        Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\n",
    "        Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
    "        \"\"\"),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "table_selection_chain={\"input\":itemgetter(\"question\"),\"table_names\":itemgetter(\"table_names\")}|TABLE_SELECTION_PROMPT|llm|CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table description  Table Name:baggage_details\n",
      "Table Description:This table stores the high-level details of each piece of baggage.  This table provides a comprehensive overview of each piece of baggage, useful for tracking and auditing purposes.\n",
      "\n",
      "\n",
      "Table Name:baggage_scanning\n",
      "Table Description:This table records the scanning details of each bag at various points in the journey. This table is crucial for monitoring the real-time status and movement of baggage, enabling proactive issue resolution and customer service.\n",
      "\n",
      "\n",
      "Table Name:passenger_details\n",
      "Table Description:This table stores information about the passengers traveling with the bags. This table allows airlines to associate passengers with their baggage, which is essential for handling rush bags where passengers and their bags might travel on different flights. It also facilitates personalized service and handling of lost baggage claims.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "table_details = pd.read_csv(\"./table_details.csv\")\n",
    "\n",
    "table_description_array = []\n",
    "for index, row in table_details.iterrows():\n",
    "    table_description_array.append(\"Table Name:\" + row['TableName'] + \"\\n\" + \"Table Description:\" + row['Description'] + \"\\n\\n\")\n",
    "\n",
    "table_description = '\\n'.join(table_description_array)\n",
    "print(\"Table description \", table_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baggage_details', 'baggage_scanning', 'passenger_details']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_selection_chain.invoke({\"question\":\"List all the flight names?\",\n",
    "                             \"table_names\":table_description})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incoming query text='SELECT \"passenger_flight_number\" FROM \"passenger_details\" WHERE \"passenger_name\" = \\'John Smith\\';'\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_community.chat_message_histories.dynamodb import DynamoDBChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# Create a query chain\n",
    "query_chain = create_sql_query_chain(llm, db,prompt=SQL_QUERY_PROMPT_WITH_MEMORY) | SQlExtractParser()\n",
    "\n",
    "current_session_id=\"Hello1\"\n",
    "\n",
    "# Create an execution chain\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "execute_chain = itemgetter(\"query\") | execute_query\n",
    "\n",
    "# Create an answer chain\n",
    "answer_chain = ANSWER_PROMPTS | llm | StrOutputParser()\n",
    "\n",
    "# Combine the chains\n",
    "final_chain = (\n",
    "    RunnablePassthrough()\n",
    "    .assign(table_names_to_use=table_selection_chain)\n",
    "    .assign(query=query_chain)\n",
    "    .assign(result=execute_chain)\n",
    "    | answer_chain\n",
    ")\n",
    "\n",
    "# Invoke the chain with the user's query\n",
    "input_data = {\n",
    "    \"question\": \"Which flight has the passenger John Smith travelled?\",\n",
    "    \"dialect\": \"sqlite\",\n",
    "    \"top_k\":2,\n",
    "    \"table_names\": table_description,\n",
    "}\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    final_chain,\n",
    "    lambda session_id: DynamoDBChatMessageHistory(\n",
    "        table_name=\"SessionTable\", \n",
    "        session_id=session_id,\n",
    "        history_size=10\n",
    "        ),\n",
    "        input_messages_key=\"question\",\n",
    "        history_messages_key=\"messages\",\n",
    ")\n",
    "config = {\n",
    "    \"configurable\": {\"session_id\": current_session_id}\n",
    "    }\n",
    "answer=chain_with_history.invoke(input_data, config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Smith has traveled on flight BC101.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incoming query text='SELECT \"origin\" FROM baggage_details WHERE \"pnr\" = \\'AAA100\\';'\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\": \"from where the fligt originated\",\n",
    "    \"dialect\": \"sqlite\",\n",
    "    \"top_k\":2,\n",
    "    \"table_names\": table_description,\n",
    "}\n",
    "answer=chain_with_history.invoke(input_data, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The flight originated from JFK.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incoming query text='SELECT \"destination\" FROM baggage_details WHERE \"pnr\" = \\'AAA100\\';'\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\": \"What is the flight destination\",\n",
    "    \"dialect\": \"sqlite\",\n",
    "    \"top_k\":2,\n",
    "    \"table_names\": table_description,\n",
    "}\n",
    "answer=chain_with_history.invoke(input_data, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The flight destination is San Francisco (SFO).'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incoming query text='SQLQuery: SELECT \"bag_tag_number\" FROM passenger_details WHERE \"passenger_name\" = \\'John Smith\\';'\n",
      "Extracted SQL query: SELECT \"bag_tag_number\" FROM passenger_details WHERE \"passenger_name\" = 'John Smith';\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\": \"List his bag tag numbers\",\n",
    "    \"dialect\": \"sqlite\",\n",
    "    \"top_k\":2,\n",
    "    \"table_names\": table_description,\n",
    "}\n",
    "answer=chain_with_history.invoke(input_data, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your bag tag number is 001234567890, John Smith.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
